#!/usr/bin/env python
# coding: utf-8

# # A notebook to create convoluted bulk mRNA-seq samples for processing

# In[11]:


import os
from os.path import join
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import ipynb
import subprocess
from glob import glob

from ipynb.fs.full.python_cmd_tools import *


# # load sample meta data

# In[2]:


# Env variables
envs = [line.strip().split() for line in open('./env_paths')]
envs = {i[0]: i[1] for i in envs}


# In[3]:


# generated by NextFlow in fist step
sample_sheet = join(envs['MAQC_DATA'], 'samplesheet/samplesheet.csv')
sample_sheet = pd.read_csv(sample_sheet)


# In[4]:


# select the .fastq files that are bulk
bulk_samples = sample_sheet[sample_sheet.experiment_title.str.contains('bulk')]
bulk_samples = bulk_samples.reset_index(drop=True)


# In[5]:


bulk_samples[['sample_title', 'experiment_title', 'run_alias', 'library_source', 'read_count', 'sample_description', 'description']]#.loc[:, 'experiment_title'][1]


# # prepare the convoluted samples for testing

# Each cell line has a single paired end library which has been sequenced three times.
# 
# I will create three samples from the first replicate of HCC1395 with 10%, 50%, and 90% contamination from HCC1395 BL

# In[6]:


f_cancer = bulk_samples.loc[5].fastq_1.replace('/run/media/ian', '/home/jovyan')
r_cancer = bulk_samples.loc[5].fastq_2.replace('/run/media/ian', '/home/jovyan')

f_bcell = bulk_samples.loc[0].fastq_1.replace('/run/media/ian', '/home/jovyan')
r_bcell = bulk_samples.loc[0].fastq_2.replace('/run/media/ian', '/home/jovyan')


# In[7]:


get_ipython().system(' mkdir -p ./output')


# In[8]:


get_ipython().run_cell_magic('time', '', "\nconv_portions = [.10, .50, .90]\nfile_pairs = [[f_cancer, f_bcell, 1], [r_cancer, r_bcell, 2]]\nout_path = './output'\nfor cp in conv_portions:\n    for fp in file_pairs:\n        file_name = str(cp * 100).replace('.0', 'Percent')\n        fA = fp[0]\n        fB = fp[1]\n        direction = str(fp[2])\n        output_fastq = join(out_path, 'conv_'+file_name+'_'+direction+'.fastq')\n        convolute_raw_data(fA, fB, output_fastq, cp)")


# Check that new files have the correct number of reads

# In[21]:


get_ipython().run_cell_magic('time', '', "\nnew_files = glob(out_path+'/*')\np_conv = [10, 50, 90]\nfor p in p_conv:\n    temp_list = [i for i in new_files if str(p) in i]\n    tf0 = temp_list[0]\n    tf1 = temp_list[1]\n    assert count_fastq_reads(tf0) == count_fastq_reads(tf1)")


# In[ ]:




